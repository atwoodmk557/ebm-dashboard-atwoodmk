ORGANIZATIONAL EVIDENCE APPRAISAL - MODULE 9: 10 BARRIERS FRAMEWORK
Document Created: November 21, 2025
Data Source: BLS Occupational Employment & Wage Statistics (OEWS)

APPLYING THE 10 BARRIERS TO BLS ORGANIZATIONAL DATA

BARRIER 1: NO LOGIC MODEL
Does it apply? NO ✅
Severity: N/A
Assessment: Data collection was hypothesis-driven with clear X→Y logic model:
  X (Coaching Turnover) → Y (Performance Decline)
BLS employment data selected specifically to understand coaching profession 
stability and employment trends in educational services sector. However, BLS 
data does NOT directly measure turnover (X) or performance (Y) - it measures 
total employment levels, which is a LIMITED proxy for workforce stability.

BARRIER 2: IRRELEVANT INDICATORS  
Does it apply? PARTIALLY ⚠️
Severity: MODERATE
Assessment: Total employment is NOT the ideal indicator for coaching turnover.
- Wanted: Coaching job change rates, tenure duration, turnover rates
- Got: Total number of coaching jobs in economy
- Problem: Employment level can remain stable even with HIGH turnover if jobs 
  are quickly refilled. Measuring "how many coaching jobs exist" ≠ measuring 
  "how often coaches change jobs."
- Mitigation: Acknowledged limitation; used employment trends as CONTEXT rather 
  than direct evidence of turnover.

BARRIER 3: LACK OF OBJECTIVITY
Does it apply? NO ✅
Severity: N/A
Assessment: BLS uses standardized survey methodology with objective employment 
counts. No subjective judgment involved. Data collected through employer surveys 
with established protocols. High objectivity.

BARRIER 4: MISSING CONTEXT
Does it apply? NO ✅ (after analysis)
Severity: N/A
Assessment: Initially, raw numbers (306,500 coaches) lack context. Analysis 
provided context through:
- 10-year historical trend (26.2% growth)
- Industry comparison (Educational Services = 28.6%)
- Geographic comparison (Iowa vs. national average)
- Benchmark: compared to population-adjusted rates
Adequate context established for interpretation.

BARRIER 5: MEASUREMENT ERROR
Does it apply? YES, MINOR ⚠️
Severity: LOW
Assessment: BLS OEWS uses sampling methodology with inherent error:
- Relative Standard Error (RSE) provided for estimates
- National data: RSE typically <2% (high reliability)
- State data (Iowa): RSE may be 3-5% (moderate reliability)
- Educational Services sector: Large sample, low error
- Error disclosed in BLS documentation
Impact: Minimal - national trends reliable; state-level estimates have acceptable 
error margins for descriptive analysis.

BARRIER 6: SMALL NUMBER PROBLEM
Does it apply? NO ✅ (for national data)
Severity: N/A
Assessment: National sample is LARGE:
- 306,500 total coaches
- 87,600 in educational services
- Sample size adequate for reliable estimates
State-level data (Iowa: 4,590) is smaller but still sufficiently large to avoid 
distortion. No small number problem for primary analysis.

BARRIER 7: BASE RATE NEGLECT
Does it apply? NO ✅
Severity: N/A
Assessment: All growth rates calculated with proper baselines:
- "26.2% growth" explicitly shows base year (2014: 242,900) and end year 
  (2024: 306,500)
- Absolute changes (+63,600 jobs) reported alongside percentages
- No misleading relative increases without base rates
Proper statistical reporting maintained throughout.

BARRIER 8: MISLEADING VISUALIZATION
Does it apply? NO ✅
Severity: N/A  
Assessment: Analysis uses tables with clear baselines. If visualizations were 
created, they would include:
- Zero baselines on bar charts
- Clearly labeled axes
- Appropriate scales
- No truncated y-axes to exaggerate trends
No misleading visual representations used.

BARRIER 9: SPURIOUS CORRELATIONS / WEAK RELATIONSHIPS
Does it apply? NOT APPLICABLE ✅
Severity: N/A
Assessment: BLS data is DESCRIPTIVE only - no correlations calculated. Did NOT 
attempt to correlate employment levels with performance outcomes. 
ACKNOWLEDGED: BLS data cannot test X→Y hypothesis without performance data.
No risk of spurious correlations because no correlational analysis performed.
Appropriate restraint in claims made from data.

BARRIER 10: WIDE CONFIDENCE INTERVALS / HIGH VARIABILITY
Does it apply? NO ✅
Severity: N/A
Assessment: BLS data shows STABLE, CONSISTENT trends:
- Steady growth across all time periods (except COVID dip)
- Low standard errors reported for estimates
- Variability within expected range for labor market data
- No wild fluctuations or unreliable estimates
Confidence intervals sufficiently narrow for descriptive conclusions.

===========================================================================
OVERALL CONFIDENCE ASSESSMENT
===========================================================================

Trustworthiness of BLS Data: HIGH ✅

Strengths:
✅ Objective, standardized government data collection
✅ Large sample sizes (national and state levels)
✅ 10-year longitudinal data shows reliable trends
✅ Clear methodology and documentation
✅ Low measurement error (RSE <2-5%)
✅ Proper context and baselines provided

Weaknesses:
⚠️ Does NOT measure actual coaching turnover (Barrier 2: Irrelevant Indicator)
⚠️ Employment levels ≠ job change rates
⚠️ Cannot directly test X→Y hypothesis without performance data

APPLICABILITY TO RESEARCH QUESTION:

Can BLS data answer "Does coaching turnover lead to performance decline"?
❌ NO - BLS data measures employment levels, not turnover or performance.

Can BLS data provide organizational context?
✅ YES - BLS data shows coaching profession is stable and growing, educational 
services is largest employer sector, and Iowa coaching employment aligns with 
state size.

CONCLUSION:
BLS organizational data has HIGH QUALITY but LIMITED RELEVANCE to core research 
question. Data provides valuable CONTEXT about coaching profession stability but 
does NOT directly measure key variables (turnover rates, performance outcomes). 

RECOMMENDATION:
BLS data should be reported as BACKGROUND/CONTEXT. Primary organizational evidence 
must come from NCAA records, athletics department reports, or university data that 
tracks actual coaching changes and team performance over time.

Confidence in BLS Data Quality: 85% HIGH
Confidence BLS Answers Research Question: 25% LOW (wrong variables measured)

===========================================================================

AI ASSISTANCE DOCUMENTATION
AI helped with: Applying 10 Barriers framework structure, formatting
Student completed: All barrier assessments, severity ratings, identifying 
weaknesses, overall confidence evaluation, recommendation for data use

**Error Sources:** [What might make measurements unreliable]
- **Systematic Errors:** [Consistent biases in measurement]
- **Random Errors:** [Inconsistent noise in measurement]
- **Human Errors:** [Mistakes in data collection or entry]

### Bias Assessment

#### Selection Bias
**Data Availability Bias:** 
- **Risk Level:** [High/Medium/Low]
- **Issue:** [Whether missing data creates systematic bias]
- **Impact:** [How missing data might skew conclusions]

**Survivorship Bias:**
- **Risk Level:** [High/Medium/Low] 
- **Issue:** [Whether only "surviving" cases/units are included]
- **Impact:** [How this might distort understanding of problem]

#### Measurement Bias
**Gaming/Manipulation Risk:**
- **Risk Level:** [High/Medium/Low]
- **Issue:** [Whether people might manipulate data to look better]
- **Mitigation:** [How organization prevents data manipulation]

**Reporting Bias:**
- **Risk Level:** [High/Medium/Low]
- **Issue:** [Whether some results are more likely to be reported than others]
- **Impact:** [How selective reporting might affect conclusions]

#### Temporal Bias
**Timing Effects:**
- **Seasonal Variations:** [Whether problem/measures vary by season]
- **Cyclical Patterns:** [Whether business cycles affect measures]
- **Event-Driven Changes:** [Whether one-time events distort patterns]

**Historical Context:**
- **Trend Analysis Validity:** [Whether historical trends predict future patterns]
- **Contextual Changes:** [How changes in organization/environment affect data interpretation]

### Completeness Assessment

#### Data Coverage
**Time Period Coverage:**
- **Adequate Historical Data:** [Whether enough historical data exists for trend analysis]
- **Pre-Problem Baseline:** [Whether data exists from before problem emerged]
- **Comparison Periods:** [Whether data allows before/after comparisons]

**Organizational Coverage:**
- **Department/Unit Coverage:** [Which parts of organization are represented in data]
- **Geographic Coverage:** [Whether all relevant locations are included]
- **Employee/Customer Coverage:** [Whether all relevant populations are included]

#### Variable Coverage
**Comprehensive Problem Coverage:** [Whether data captures all aspects of problem]
**Outcome Measure Coverage:** [Whether data includes measures of success you care about]
**Contextual Variable Coverage:** [Whether data includes factors that might influence problem]

### Accuracy Assessment

#### Data Verification Methods
**Cross-Verification Performed:**
- **Multiple Source Comparison:** [Whether data from different sources was compared]
- **External Validation:** [Whether internal data was checked against external sources]
- **Audit Trail Review:** [Whether data collection process was verified]

**Error Detection Efforts:**
- **Outlier Analysis:** [How unusual data points were investigated]
- **Consistency Checks:** [How data inconsistencies were identified and resolved]
- **Logic Validation:** [How impossible or illogical values were caught]

#### Accuracy Limitations
**Known Data Errors:** [Specific errors identified in the data]
**Estimated Error Rates:** [Best guess at how much error exists in data]
**Impact of Errors:** [How data errors might affect conclusions]

## Organizational Context Assessment

### Data Collection Environment

#### Organizational Culture Impact
**Data Culture Assessment:** [How organization values data quality and accuracy]
- **Data Quality Priority:** [High/Medium/Low] - [Evidence for assessment]
- **Transparency Level:** [How open organization is about problems and data]
- **Accountability Systems:** [How organization ensures data accuracy]

**Political Factors:**
- **Pressure to Show Improvement:** [Whether there's pressure to manipulate data positively]
- **Blame Culture Impact:** [Whether fear of blame affects honest reporting]
- **Resource Competition:** [Whether departments compete in ways that might affect data]

#### System Limitations
**Technology Constraints:** [How IT systems limit data quality or availability]
**Process Constraints:** [How business processes affect data collection]
**Resource Constraints:** [How limited resources affect data quality]

### Stakeholder Influence Assessment

#### Data Provider Credibility
**Data Collectors/Managers:**
- **Competence Assessment:** [How skilled are people who collect/manage this data]
- **Motivation Assessment:** [What motivates data collectors - accuracy vs. other priorities]
- **Training Assessment:** [How well-trained are data collectors]

**Data Users/Interpreters:**
- **Analytical Skills:** [How capable are people who analyze this data normally]
- **Bias Awareness:** [How aware are normal users of data limitations]
- **Decision Integration:** [How well this data typically informs decisions]

## Context-Specific Reliability

### Problem-Specific Assessment
**Problem Detection Capability:** [How well this data can identify your specific problem]
**Problem Severity Assessment:** [How well this data can measure problem severity]
**Solution Impact Measurement:** [How well this data could measure solution effectiveness]

### Decision-Making Utility
**Actionability:** [How well this data supports specific decisions]
**Timeliness:** [Whether data is available soon enough to inform decisions]
**Granularity:** [Whether data is detailed enough for your decision needs]

## Quality Rating by Data Category

### Performance Metrics
**Overall Quality Rating:** [High/Medium/Low]
**Strengths:** [What makes this performance data reliable]
**Limitations:** [What limits confidence in performance data]
**Decision Support Value:** [How useful this data is for decisions]

### Financial Data
**Overall Quality Rating:** [High/Medium/Low]
**Strengths:** [What makes financial data reliable]
**Limitations:** [What limits confidence in financial data]
**Decision Support Value:** [How useful financial data is for decisions]

### Operational Data
**Overall Quality Rating:** [High/Medium/Low]
**Strengths:** [What makes operational data reliable]
**Limitations:** [What limits confidence in operational data]
**Decision Support Value:** [How useful operational data is for decisions]

### Customer/Market Data
**Overall Quality Rating:** [High/Medium/Low]
**Strengths:** [What makes customer/market data reliable]
**Limitations:** [What limits confidence in customer/market data]
**Decision Support Value:** [How useful customer/market data is for decisions]

## Overall Organizational Evidence Assessment

### Strengths of Organizational Evidence
[List the 3-5 strongest aspects of your organizational data]

### Limitations of Organizational Evidence
[List the 3-5 most significant limitations in your organizational data]

### Confidence Level for Decision-Making
**Overall Confidence:** [High/Medium/Low]
**Justification:** [Explain why you have this level of confidence in organizational data]

### Recommendations for Data Improvement
[What could be done to strengthen organizational evidence for future decisions]

### Integration with Other Evidence Types
**Complementary Evidence Needs:** [What other evidence types help offset limitations in organizational data]
**Triangulation Opportunities:** [How organizational data can be validated against other evidence]

---
INSTRUCTIONS:
1. Be honest about data limitations - perfect organizational data is extremely rare
2. Consider how organizational politics and culture affect data quality
3. Assess whether data actually measures what you think it measures
4. Evaluate both the technical quality and practical utility of the data
5. Consider how data quality affects confidence in your conclusions
